{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/makus/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/makus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import import_data\n",
    "import preprocessing\n",
    "import feature_extraction\n",
    "import dimension_reduction\n",
    "import classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research centercontent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subjectlang classification grimes , joseph e ....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>love your profile - ysuolvpvhello thanks for s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>you have been asked to join kiddinthe list own...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>anglicization of composers ' namesjudging from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>re : 6 . 797 , comparative method : n - ary co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>re : american - english in australiahello ! i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     job posting - apple-iss research centercontent...      0\n",
       "1     Subjectlang classification grimes , joseph e ....      0\n",
       "2     query : letter frequencies for text identifica...      0\n",
       "3     riska colleague and i are researching the diff...      0\n",
       "4     request book informationearlier this morning i...      0\n",
       "...                                                 ...    ...\n",
       "2888  love your profile - ysuolvpvhello thanks for s...      1\n",
       "2889  you have been asked to join kiddinthe list own...      1\n",
       "2890  anglicization of composers ' namesjudging from...      0\n",
       "2891  re : 6 . 797 , comparative method : n - ary co...      0\n",
       "2892  re : american - english in australiahello ! i ...      0\n",
       "\n",
       "[2893 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lingspam = import_data.create_df_from_csv('/home/makus/Documents/Semester_7_WIN2022/Bachelorarbeit/ba_code/datasets/messages.csv')\n",
    "lingspam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to illustrate the effect of our preprocessing we create a copy of the df and compare it later on with the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/makus/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/makus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 31.020194115000777 second(s) to finish preprocessing.\n"
     ]
    }
   ],
   "source": [
    "lingspam_mails = lingspam['text']\n",
    "lingspam_mails_clean = preprocessing.preprocess_only_text_format(lingspam['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction with Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data:\n",
      "It took 0.8734075510001276 second(s) to create the model and build the vocabulary.\n",
      "It took 108.20169981502113 second(s) to finish doc2vec.\n",
      "(2893, 100)\n",
      "Raw data:\n",
      "It took 1.733174824010348 second(s) to create the model and build the vocabulary.\n",
      "It took 198.54579203401227 second(s) to finish doc2vec.\n",
      "(2893, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessed data:')\n",
    "dv_mails = feature_extraction.doc2vec_vectorize(lingspam_mails_clean,100)\n",
    "print(dv_mails.shape)\n",
    "print(\"Raw data:\")\n",
    "dv_raw_mails = feature_extraction.doc2vec_vectorize(lingspam_mails,100)\n",
    "print(dv_raw_mails.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cause of predefined low dimension, we don't need dimension reduction(emprically tested: more dimensions does not increase performance of the experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data:\n",
      "It took 1.158311904000584 second(s) to finish TF-IDF feature extraction.\n",
      "Raw data:\n",
      "It took 1.6696016189816874 second(s) to finish TF-IDF feature extraction.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2893, 29059)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preprocessed data:\")\n",
    "tfidf_mails = feature_extraction.tfidf_vectorize(lingspam_mails_clean)\n",
    "tfidf_mails.shape\n",
    "print(\"Raw data:\")\n",
    "tfidf_raw_mails = feature_extraction.tfidf_vectorize(lingspam_mails)\n",
    "tfidf_raw_mails.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction with the TF-IDF vectorized mails"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data:\n",
      "It took 5.190513406996615 second(s) to finish dimension reduction with Sparse Random Projection.\n",
      "Raw data:\n",
      "It took 5.676838886021869 second(s) to finish dimension reduction with Sparse Random Projection.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2893, 6831)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preprocessed data:\")\n",
    "sparse_tfidf_mails = dimension_reduction.sparse_random_projection(tfidf_mails)\n",
    "sparse_tfidf_mails.shape\n",
    "print(\"Raw data:\")\n",
    "sparse_raw_tfidf_mails = dimension_reduction.sparse_random_projection(tfidf_raw_mails)\n",
    "sparse_raw_tfidf_mails.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce the mails set to 100 dimensions for getting the same dimensions as we get in doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data:\n",
      "It took 20.05183771700831 second(s) to finish dimension reduction with IPCA.\n",
      "Raw data:\n",
      "It took 27.459661603992572 second(s) to finish dimension reduction with IPCA.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2893, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preprocessed data:\")\n",
    "very_sparse_tfidf_mails = dimension_reduction.ipca(sparse_tfidf_mails,100)\n",
    "very_sparse_tfidf_mails.shape\n",
    "print(\"Raw data:\")\n",
    "very_sparse_raw_tfidf_mails = dimension_reduction.ipca(sparse_raw_tfidf_mails,100)\n",
    "very_sparse_raw_tfidf_mails.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: The sparse random results gives for both inputs the same dimension, but there not equal.\n",
    "TF-IDF+dimension reduction is faster than doc2vec and in both cases, the preprocessed and the not preprocessed dataset.\n",
    "The Question is: which procedure performs better on classification?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classification for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lingspam['label']\n",
    "experiment_sets = [\n",
    "    dv_mails, #preprocessed data, feature extraction with doc2vec\n",
    "    dv_raw_mails, #not preprocessed data, feature extraction with doc2vec\n",
    "    sparse_tfidf_mails, #preprocessed, tfidf, sparse random projection\n",
    "    sparse_raw_tfidf_mails, #not preprocessed, tfidf, sparse random projection\n",
    "    very_sparse_tfidf_mails, #preprocessed, tfidf, sparse random projection, ipca\n",
    "    very_sparse_raw_tfidf_mails] #not-preprocessed, tfidf, sparse random projection, ipca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set Index</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F_one_Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.513850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.699482</td>\n",
       "      <td>0.819502</td>\n",
       "      <td>0.497961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.943005</td>\n",
       "      <td>0.967294</td>\n",
       "      <td>71.801906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.956822</td>\n",
       "      <td>0.975025</td>\n",
       "      <td>72.599672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.941278</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>0.349729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.955095</td>\n",
       "      <td>0.974052</td>\n",
       "      <td>0.286340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set Index  Accuracy  F_one_Score       Time\n",
       "0        1.0  0.730570     0.841463   0.513850\n",
       "1        2.0  0.699482     0.819502   0.497961\n",
       "2        3.0  0.943005     0.967294  71.801906\n",
       "3        4.0  0.956822     0.975025  72.599672\n",
       "4        5.0  0.941278     0.966337   0.349729\n",
       "5        6.0  0.955095     0.974052   0.286340"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "i = 1\n",
    "feature_extraction_report = pd.DataFrame(columns=['Set Index','Accuracy','F_one_Score','Time'])\n",
    "for set in experiment_sets:\n",
    "    start = perf_counter()\n",
    "    report, X_test, y_test, y_pred = classification.svm(set,y,noisy = False)\n",
    "    end = perf_counter()\n",
    "    acc = report[\"accuracy\"][0]\n",
    "    f_one = report.get(\"0\",{}).get(\"f1-score\")\n",
    "    time = end - start\n",
    "    feature_extraction_report.loc[len(feature_extraction_report)] = [i, acc, f_one,time]\n",
    "    i += 1\n",
    "\n",
    "feature_extraction_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "For our intended use the following method is recommended:\n",
    "\n",
    "TF-IDF -> Random Projection -> Incremental PCA without preprocessing\n",
    "\n",
    "It produces the best results when you include the computation speed.\n",
    "For the rest of our experiment, we only use this method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
